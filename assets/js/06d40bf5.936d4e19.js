"use strict";(globalThis.webpackChunkproject=globalThis.webpackChunkproject||[]).push([[9944],{7572:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"chapter-6-sensor-integration","title":"Chapter 6 - Sensor Integration Concepts","description":"Introduction to Sensor Integration in Humanoid Robotics","source":"@site/docs/chapter-6-sensor-integration.md","sourceDirName":".","slug":"/chapter-6-sensor-integration","permalink":"/docs/chapter-6-sensor-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter-6-sensor-integration.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"Chapter 6 - Sensor Integration Concepts"},"sidebar":"bookSidebar","previous":{"title":"Chapter 5 - Conceptual Overview of Simulation Technologies","permalink":"/docs/chapter-5-simulation-technologies"},"next":{"title":"Chapter 7 - Basic Cognitive Models for Humanoids","permalink":"/docs/chapter-7-cognitive-models"}}');var r=i(4848),t=i(8453);const o={sidebar_position:7,title:"Chapter 6 - Sensor Integration Concepts"},l="Chapter 6: Sensor Integration Concepts",a={},c=[{value:"Introduction to Sensor Integration in Humanoid Robotics",id:"introduction-to-sensor-integration-in-humanoid-robotics",level:2},{value:"Types of Sensors in Humanoid Robots",id:"types-of-sensors-in-humanoid-robots",level:2},{value:"Proprioceptive Sensors",id:"proprioceptive-sensors",level:3},{value:"Joint Position Sensors",id:"joint-position-sensors",level:4},{value:"Joint Torque Sensors",id:"joint-torque-sensors",level:4},{value:"Inertial Measurement Units (IMUs)",id:"inertial-measurement-units-imus",level:4},{value:"Exteroceptive Sensors",id:"exteroceptive-sensors",level:3},{value:"Vision Systems",id:"vision-systems",level:4},{value:"Range Sensors",id:"range-sensors",level:4},{value:"Tactile Sensors",id:"tactile-sensors",level:4},{value:"Sensor Fusion Fundamentals",id:"sensor-fusion-fundamentals",level:2},{value:"Data-Level Fusion",id:"data-level-fusion",level:3},{value:"Feature-Level Fusion",id:"feature-level-fusion",level:3},{value:"Decision-Level Fusion",id:"decision-level-fusion",level:3},{value:"Mathematical Foundations",id:"mathematical-foundations",level:2},{value:"Kalman Filtering",id:"kalman-filtering",level:3},{value:"Extended Kalman Filter (EKF)",id:"extended-kalman-filter-ekf",level:3},{value:"Particle Filtering",id:"particle-filtering",level:3},{value:"Sensor Integration Architectures",id:"sensor-integration-architectures",level:2},{value:"Centralized Architecture",id:"centralized-architecture",level:3},{value:"Distributed Architecture",id:"distributed-architecture",level:3},{value:"Hierarchical Architecture",id:"hierarchical-architecture",level:3},{value:"Time Synchronization",id:"time-synchronization",level:2},{value:"Hardware Synchronization",id:"hardware-synchronization",level:3},{value:"Software Synchronization",id:"software-synchronization",level:3},{value:"Interpolation and Extrapolation",id:"interpolation-and-extrapolation",level:3},{value:"Conceptual Exercise 6.1: Sensor Placement for Humanoid Balance",id:"conceptual-exercise-61-sensor-placement-for-humanoid-balance",level:2},{value:"Communication Protocols",id:"communication-protocols",level:2},{value:"Real-time Communication",id:"real-time-communication",level:3},{value:"High-Bandwidth Communication",id:"high-bandwidth-communication",level:3},{value:"Sensor Calibration",id:"sensor-calibration",level:2},{value:"Intrinsic Calibration",id:"intrinsic-calibration",level:3},{value:"Extrinsic Calibration",id:"extrinsic-calibration",level:3},{value:"Fault Detection and Tolerance",id:"fault-detection-and-tolerance",level:2},{value:"Sensor Health Monitoring",id:"sensor-health-monitoring",level:3},{value:"Redundancy Strategies",id:"redundancy-strategies",level:3},{value:"Recovery Strategies",id:"recovery-strategies",level:3},{value:"Integration with Control Systems",id:"integration-with-control-systems",level:2},{value:"Feedback Control",id:"feedback-control",level:3},{value:"State Estimation",id:"state-estimation",level:3},{value:"Performance Evaluation",id:"performance-evaluation",level:2},{value:"Accuracy Metrics",id:"accuracy-metrics",level:3},{value:"Timeliness Metrics",id:"timeliness-metrics",level:3},{value:"Emerging Sensor Technologies",id:"emerging-sensor-technologies",level:2},{value:"Event-Based Sensors",id:"event-based-sensors",level:3},{value:"Neuromorphic Sensors",id:"neuromorphic-sensors",level:3},{value:"Summary",id:"summary",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"chapter-6-sensor-integration-concepts",children:"Chapter 6: Sensor Integration Concepts"})}),"\n",(0,r.jsx)(e.h2,{id:"introduction-to-sensor-integration-in-humanoid-robotics",children:"Introduction to Sensor Integration in Humanoid Robotics"}),"\n",(0,r.jsx)(e.p,{children:"Humanoid robots require sophisticated sensor integration to perceive and interact with their environment effectively. Unlike simpler robots, humanoid systems must process multiple sensor modalities simultaneously to achieve human-like awareness and capabilities. This chapter explores the concepts and challenges of integrating diverse sensors into cohesive perception systems."}),"\n",(0,r.jsx)(e.h2,{id:"types-of-sensors-in-humanoid-robots",children:"Types of Sensors in Humanoid Robots"}),"\n",(0,r.jsx)(e.h3,{id:"proprioceptive-sensors",children:"Proprioceptive Sensors"}),"\n",(0,r.jsx)(e.p,{children:"Sensors that measure the robot's internal state:"}),"\n",(0,r.jsx)(e.h4,{id:"joint-position-sensors",children:"Joint Position Sensors"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Technology"}),": Encoders, potentiometers, magnetic sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Purpose"}),": Measure joint angles for control and kinematic calculations"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Characteristics"}),": High precision, high frequency, direct feedback"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Joint control, kinematic state estimation, safety monitoring"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"joint-torque-sensors",children:"Joint Torque Sensors"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Technology"}),": Strain gauges, force sensing resistors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Purpose"}),": Measure forces and torques at joints"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Characteristics"}),": Critical for compliant control and interaction"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Force control, contact detection, safety"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"inertial-measurement-units-imus",children:"Inertial Measurement Units (IMUs)"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Technology"}),": Accelerometers, gyroscopes, magnetometers"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Purpose"}),": Measure orientation, angular velocity, and linear acceleration"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Characteristics"}),": High frequency, drift over time"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Balance control, orientation estimation, motion detection"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"exteroceptive-sensors",children:"Exteroceptive Sensors"}),"\n",(0,r.jsx)(e.p,{children:"Sensors that perceive the external environment:"}),"\n",(0,r.jsx)(e.h4,{id:"vision-systems",children:"Vision Systems"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Technology"}),": RGB cameras, stereo cameras, depth cameras"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Purpose"}),": Visual perception of environment"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Characteristics"}),": Rich information, computationally intensive"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Object recognition, navigation, human interaction"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"range-sensors",children:"Range Sensors"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Technology"}),": LIDAR, ultrasonic sensors, infrared sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Purpose"}),": Distance measurement to objects"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Characteristics"}),": Accurate distance, limited field of view"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Obstacle detection, mapping, navigation"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"tactile-sensors",children:"Tactile Sensors"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Technology"}),": Force sensing arrays, pressure sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Purpose"}),": Touch and contact information"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Characteristics"}),": High spatial resolution, real-time response"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Grasping, manipulation, human interaction"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"sensor-fusion-fundamentals",children:"Sensor Fusion Fundamentals"}),"\n",(0,r.jsx)(e.h3,{id:"data-level-fusion",children:"Data-Level Fusion"}),"\n",(0,r.jsx)(e.p,{children:"Combining raw sensor data before processing:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),": Preserves all information, optimal for correlated sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),": High computational requirements, sensor synchronization needed"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Multi-camera systems, multi-modal sensing"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"feature-level-fusion",children:"Feature-Level Fusion"}),"\n",(0,r.jsx)(e.p,{children:"Combining processed features from different sensors:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),": Reduced computational load, modular processing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),": Potential information loss, feature compatibility issues"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Object detection, tracking systems"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"decision-level-fusion",children:"Decision-Level Fusion"}),"\n",(0,r.jsx)(e.p,{children:"Combining decisions or classifications from different sensors:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),": Maximum modularity, easy to implement"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),": Significant information loss, suboptimal performance"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Final classification, system-level decisions"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"mathematical-foundations",children:"Mathematical Foundations"}),"\n",(0,r.jsx)(e.h3,{id:"kalman-filtering",children:"Kalman Filtering"}),"\n",(0,r.jsx)(e.p,{children:"Kalman filters provide optimal state estimation for linear systems with Gaussian noise:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"Prediction: x\u0302\u2096|\u2096\u208b\u2081 = F\u2096x\u0302\u2096\u208b\u2081|\u2096\u208b\u2081 + B\u2096u\u2096\r\nUpdate: x\u0302\u2096|\u2096 = x\u0302\u2096|\u2096\u208b\u2081 + K\u2096(z\u2096 - H\u2096x\u0302\u2096|\u2096\u208b\u2081)\n"})}),"\n",(0,r.jsx)(e.p,{children:"For humanoid robots, Kalman filters are used for:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"State estimation (position, velocity, orientation)"}),"\n",(0,r.jsx)(e.li,{children:"Sensor noise reduction"}),"\n",(0,r.jsx)(e.li,{children:"Prediction of future states"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"extended-kalman-filter-ekf",children:"Extended Kalman Filter (EKF)"}),"\n",(0,r.jsx)(e.p,{children:"For non-linear systems, the EKF linearizes around the current state estimate:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": IMU integration, visual-inertial odometry"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),": Handles non-linear dynamics"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),": Linearization errors, computational complexity"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"particle-filtering",children:"Particle Filtering"}),"\n",(0,r.jsx)(e.p,{children:"Particle filters represent probability distributions with samples:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Multi-modal state estimation, non-Gaussian noise"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),": Handles complex distributions, non-linear systems"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),": High computational requirements, particle degeneracy"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"sensor-integration-architectures",children:"Sensor Integration Architectures"}),"\n",(0,r.jsx)(e.h3,{id:"centralized-architecture",children:"Centralized Architecture"}),"\n",(0,r.jsx)(e.p,{children:"All sensor data processed by a central unit:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),": Optimal fusion, global optimization"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),": Single point of failure, computational bottleneck"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Research platforms, low-sensor-count systems"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"distributed-architecture",children:"Distributed Architecture"}),"\n",(0,r.jsx)(e.p,{children:"Sensors processed by local units with coordination:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),": Scalability, fault tolerance, reduced communication"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),": Suboptimal fusion, coordination complexity"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Production humanoid robots, real-time systems"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"hierarchical-architecture",children:"Hierarchical Architecture"}),"\n",(0,r.jsx)(e.p,{children:"Multiple levels of processing and fusion:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),": Balanced approach, modularity"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),": Complex design, coordination requirements"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Complex humanoid systems, multi-robot systems"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"time-synchronization",children:"Time Synchronization"}),"\n",(0,r.jsx)(e.h3,{id:"hardware-synchronization",children:"Hardware Synchronization"}),"\n",(0,r.jsx)(e.p,{children:"Using common clock signals or triggers:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Methods"}),": PTP (Precision Time Protocol), shared clock lines"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Accuracy"}),": Microsecond-level synchronization"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": High-precision systems, multi-camera setups"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"software-synchronization",children:"Software Synchronization"}),"\n",(0,r.jsx)(e.p,{children:"Adjusting timestamps based on known delays:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Methods"}),": Network time protocols, delay compensation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Accuracy"}),": Millisecond-level synchronization"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Most robotic systems, ROS time synchronization"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"interpolation-and-extrapolation",children:"Interpolation and Extrapolation"}),"\n",(0,r.jsx)(e.p,{children:"Handling data with different update rates:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Interpolation"}),": Estimating values between samples"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Extrapolation"}),": Predicting future values"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Multi-rate sensor fusion, real-time control"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"conceptual-exercise-61-sensor-placement-for-humanoid-balance",children:"Conceptual Exercise 6.1: Sensor Placement for Humanoid Balance"}),"\n",(0,r.jsx)(e.p,{children:"Design a sensor system for a humanoid robot that needs to maintain balance on uneven terrain. Consider:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"What types of sensors are most critical for balance control?"}),"\n",(0,r.jsx)(e.li,{children:"Where should these sensors be placed on the robot's body?"}),"\n",(0,r.jsx)(e.li,{children:"What are the trade-offs between sensor accuracy and computational load?"}),"\n",(0,r.jsx)(e.li,{children:"How would you handle sensor failures or noisy data?"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"communication-protocols",children:"Communication Protocols"}),"\n",(0,r.jsx)(e.h3,{id:"real-time-communication",children:"Real-time Communication"}),"\n",(0,r.jsx)(e.p,{children:"For time-critical sensor data:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"CAN Bus"}),": Deterministic communication, widely used in robotics"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"EtherCAT"}),": High-speed, real-time communication"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Time-Triggered Protocols"}),": Guaranteed timing for critical data"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"high-bandwidth-communication",children:"High-Bandwidth Communication"}),"\n",(0,r.jsx)(e.p,{children:"For sensor data requiring high throughput:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"GigE Vision"}),": For high-resolution cameras"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"10GbE"}),": For multiple high-bandwidth sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"PCIe"}),": For sensors directly connected to processing units"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"sensor-calibration",children:"Sensor Calibration"}),"\n",(0,r.jsx)(e.h3,{id:"intrinsic-calibration",children:"Intrinsic Calibration"}),"\n",(0,r.jsx)(e.p,{children:"Calibrating internal sensor parameters:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Camera Calibration"}),": Focal length, principal point, distortion"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"IMU Calibration"}),": Bias, scale factor, alignment"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"LIDAR Calibration"}),": Range accuracy, angular precision"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"extrinsic-calibration",children:"Extrinsic Calibration"}),"\n",(0,r.jsx)(e.p,{children:"Calibrating sensor positions and orientations relative to the robot:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Hand-Eye Calibration"}),": Sensor position relative to end-effector"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Body Frame Calibration"}),": Sensor position relative to robot links"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Multi-Sensor Calibration"}),": Relative positions between sensors"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"fault-detection-and-tolerance",children:"Fault Detection and Tolerance"}),"\n",(0,r.jsx)(e.h3,{id:"sensor-health-monitoring",children:"Sensor Health Monitoring"}),"\n",(0,r.jsx)(e.p,{children:"Continuous monitoring of sensor status:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Methods"}),": Range checking, consistency checking, temporal analysis"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Safety systems, graceful degradation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Implementation"}),": Real-time monitoring algorithms"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"redundancy-strategies",children:"Redundancy Strategies"}),"\n",(0,r.jsx)(e.p,{children:"Using multiple sensors for critical functions:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Spatial Redundancy"}),": Multiple sensors at different locations"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Modal Redundancy"}),": Different sensor types measuring same quantity"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Temporal Redundancy"}),": Multiple measurements over time"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"recovery-strategies",children:"Recovery Strategies"}),"\n",(0,r.jsx)(e.p,{children:"Handling sensor failures gracefully:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Fallback Modes"}),": Reduced functionality with remaining sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Reconfiguration"}),": Adapt algorithms to available sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Safe States"}),": Return to safe configuration when critical sensors fail"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"integration-with-control-systems",children:"Integration with Control Systems"}),"\n",(0,r.jsx)(e.h3,{id:"feedback-control",children:"Feedback Control"}),"\n",(0,r.jsx)(e.p,{children:"Using sensor data for closed-loop control:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Position Control"}),": Joint position feedback"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Force Control"}),": Force/torque feedback"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Impedance Control"}),": Combined position/force control"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"state-estimation",children:"State Estimation"}),"\n",(0,r.jsx)(e.p,{children:"Estimating complete robot state from sensor data:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Kinematic State"}),": Position and orientation of all links"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Dynamic State"}),": Velocities, accelerations, forces"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Environmental State"}),": Position of objects, terrain properties"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"performance-evaluation",children:"Performance Evaluation"}),"\n",(0,r.jsx)(e.h3,{id:"accuracy-metrics",children:"Accuracy Metrics"}),"\n",(0,r.jsx)(e.p,{children:"Quantifying sensor system performance:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Precision"}),": Repeatability of measurements"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Accuracy"}),": Closeness to true values"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Resolution"}),": Smallest detectable change"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"timeliness-metrics",children:"Timeliness Metrics"}),"\n",(0,r.jsx)(e.p,{children:"Evaluating temporal performance:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Latency"}),": Delay from measurement to availability"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Jitter"}),": Variation in latency"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Update Rate"}),": Frequency of sensor data"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"emerging-sensor-technologies",children:"Emerging Sensor Technologies"}),"\n",(0,r.jsx)(e.h3,{id:"event-based-sensors",children:"Event-Based Sensors"}),"\n",(0,r.jsx)(e.p,{children:"Sensors that respond to changes rather than continuous sampling:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Event Cameras"}),": High-speed, low-latency visual sensing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Benefits"}),": Reduced data, high temporal resolution"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Fast motion, high-dynamic-range scenarios"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"neuromorphic-sensors",children:"Neuromorphic Sensors"}),"\n",(0,r.jsx)(e.p,{children:"Bio-inspired sensors with adaptive behavior:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Concept"}),": Mimicking biological sensory systems"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Benefits"}),": Adaptive sampling, efficient processing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Applications"}),": Energy-efficient perception systems"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(e.p,{children:"Sensor integration in humanoid robotics requires careful consideration of multiple factors including sensor selection, fusion algorithms, communication protocols, and fault tolerance. The complexity of humanoid systems demands sophisticated integration approaches that can handle diverse sensor modalities while maintaining real-time performance and safety."}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Previous"}),": ",(0,r.jsx)(e.a,{href:"/docs/chapter-5-simulation-technologies",children:"Chapter 5 - Conceptual Overview of Simulation Technologies"}),"\r\n",(0,r.jsx)(e.strong,{children:"Next"}),": ",(0,r.jsx)(e.a,{href:"/docs/chapter-7-cognitive-models",children:"Chapter 7 - Basic Cognitive Models for Humanoids"})]})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>l});var s=i(6540);const r={},t=s.createContext(r);function o(n){const e=s.useContext(t);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),s.createElement(t.Provider,{value:e},n.children)}}}]);